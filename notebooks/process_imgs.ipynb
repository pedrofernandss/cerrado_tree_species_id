{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Preprocessing Pipeline ⚙️\n",
    "This notebook demonstrates the implementation of an innovative preprocessing pipeline for native tree images captured using a DJI Mavic 3M drone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import math\n",
    "from itertools import cycle , islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First steps of the image processing pipeline \n",
    "\n",
    "This first part of the script defines a set of functions that work together to correct and align images based on camera calibration metadata.\n",
    "Here's a breakdown of how each function contributes to the full workflow:\n",
    "\n",
    "1. **`get_xml_metadata(imgPath)`**  \n",
    "   Extracts metadata from the image file using ExifTool. This metadata includes calibration parameters such as optical center, vignetting coefficients, distortion data, and homography matrix.\n",
    "\n",
    "2. **`vig_correct(image_path, infoDict)`**  \n",
    "   Applies vignette correction to the image using a polynomial model. The correction is based on distance from the optical center and the vignetting coefficients retrieved from the metadata.\n",
    "\n",
    "3. **`undistort(new_img, infoDict)`**  \n",
    "   Corrects geometric distortion in the image using the camera matrix and distortion coefficients provided in the metadata.\n",
    "\n",
    "4. **`align_phase_rotation(new_img, infoDict)`**  \n",
    "   Applies a homographic transformation to align the image's perspective, correcting for phase and rotational differences due to camera setup.\n",
    "\n",
    "5. **`crop_center(img, crop_tamanho)`**  \n",
    "   Crops a centered square region of the image with the given size. This focuses the output on the most relevant region of the image.\n",
    "\n",
    "6. **`zoom_center(img, zoom_factor=1.5)`**  \n",
    "   For `.JPG` images (which have a different resolution), it crops and zooms the center area to match the target reference size.\n",
    "\n",
    "7. **`process_image(imgPath)`**  \n",
    "   The main pipeline that orchestrates all steps:\n",
    "   - Extracts metadata.\n",
    "   - Handles `.JPG` images with a separate zooming and resizing flow.\n",
    "   - Applies vignette correction, distortion correction, and alignment for other formats.\n",
    "   - Crops the central region to finalize the processed image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T12:59:18.221899Z",
     "iopub.status.busy": "2024-05-27T12:59:18.221471Z",
     "iopub.status.idle": "2024-05-27T12:59:18.247982Z",
     "shell.execute_reply": "2024-05-27T12:59:18.246236Z",
     "shell.execute_reply.started": "2024-05-27T12:59:18.221861Z"
    },
    "id": "Iry3p3ktYq_K",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_xml_metadata(imgPath):\n",
    "  \"\"\"\n",
    "      get XML metadata\n",
    "      This function retrieves metadata from an image file using ExifTool.\n",
    "      Parameters:\n",
    "      - imgPath: Path to the image file.\n",
    "      Returns:\n",
    "      - infoDict: Dictionary containing metadata tags and their values.\n",
    "  \"\"\"\n",
    "\n",
    "  infoDict = {}\n",
    "  exifToolPath = 'exiftool'\n",
    "  ''' use Exif tool to get the metadata '''\n",
    "  process = subprocess.Popen([exifToolPath,imgPath],stdout=subprocess.PIPE, stderr=subprocess.STDOUT,universal_newlines=True)\n",
    "  ''' get the tags in dict '''\n",
    "  for tag in process.stdout:\n",
    "      line = tag.strip().split(':')\n",
    "      infoDict[line[0].strip()] = line[-1].strip()\n",
    "  return infoDict\n",
    "\n",
    "\n",
    "def vig_correct(image_path, infoDict):\n",
    "  \"\"\"\n",
    "    Vignette Correction\n",
    "    This function applies a vignette correction to an image based on the provided calibration data.\n",
    "    Parameters:\n",
    "    - image_path: Path to the image file.\n",
    "    - infoDict: Dictionary containing calibration data, including:\n",
    "        - 'Calibrated Optical Center X': X coordinate of the optical center.\n",
    "        - 'Calibrated Optical Center Y': Y coordinate of the optical center.\n",
    "        - 'Vignetting Data': Vignetting coefficients.\n",
    "    Returns:\n",
    "    - corrected_img: The vignette-corrected image as a NumPy array.\n",
    "  \"\"\"\n",
    "\n",
    "  centerX = int(float(infoDict['Calibrated Optical Center X']))\n",
    "  centerY = int(float(infoDict['Calibrated Optical Center Y']))\n",
    "  k = [float(elem.strip(\",\")) for elem in infoDict['Vignetting Data'].split()]\n",
    "\n",
    "  # Load the image\n",
    "  image = Image.open(image_path)\n",
    "  np_img = np.array(image, dtype=np.uint16)\n",
    "  rows, cols = np_img.shape[:2]\n",
    "\n",
    "  # Create meshgrid of coordinates\n",
    "  y_coords, x_coords = np.meshgrid(np.arange(rows), np.arange(cols), indexing='ij')\n",
    "\n",
    "  # Calculate the distance r for each pixel\n",
    "  r = np.sqrt((x_coords - centerX)**2 + (y_coords - centerY)**2)\n",
    "\n",
    "  # Calculate the correction factor\n",
    "  correction_factor = (\n",
    "      k[5] * r**6 +\n",
    "      k[4] * r**5 +\n",
    "      k[3] * r**4 +\n",
    "      k[2] * r**3 +\n",
    "      k[1] * r**2 +\n",
    "      k[0] * r +\n",
    "      1.0\n",
    "  )\n",
    "\n",
    "  # Apply the correction factor to the image\n",
    "  corrected_img = np_img * correction_factor[..., np.newaxis] if np_img.ndim == 3 else np_img * correction_factor\n",
    "  return corrected_img.astype('uint16')\n",
    "\n",
    "\n",
    "def undistort(new_img, infoDict):\n",
    "  \"\"\"\n",
    "    Distortion correction\n",
    "    This function undistorts an image using camera calibration data.\n",
    "    Parameters:\n",
    "    - new_img: The input image to be undistorted.\n",
    "    - infoDict: Dictionary containing calibration data, including:\n",
    "        - 'Calibrated Optical Center X': X coordinate of the optical center.\n",
    "        - 'Calibrated Optical Center Y': Y coordinate of the optical center.\n",
    "        - 'Dewarp Data': Distortion coefficients.\n",
    "    Returns:\n",
    "    - dst: The undistorted image as a NumPy array.\n",
    "  \"\"\"\n",
    "\n",
    "  centerX = int(float(infoDict['Calibrated Optical Center X']))\n",
    "  centerY = int(float(infoDict['Calibrated Optical Center Y']))\n",
    "\n",
    "  dewarp_args = [float(elem) for elem in infoDict['Dewarp Data'].split(\";\")[1].split(\",\")]\n",
    "  dist_coeffs = np.asarray(dewarp_args[4:])\n",
    "  tuple0 = (dewarp_args[0], 0, centerX + dewarp_args[2])\n",
    "  tuple1 = (0, dewarp_args[1], centerY + dewarp_args[3])\n",
    "  tuple2 = (0, 0, 1)\n",
    "  camera_matrix = np.asarray([tuple0, tuple1, tuple2])\n",
    "\n",
    "  h,  w = new_img.shape[:2]\n",
    "  _, roi=cv2.getOptimalNewCameraMatrix(camera_matrix,dist_coeffs,(w,h),1,(w,h))\n",
    "\n",
    "  dst = cv2.undistort(new_img, camera_matrix, dist_coeffs, None, camera_matrix)\n",
    "  # crop the image\n",
    "  x,y,w,h = roi\n",
    "  dst = dst[y:y+h, x:x+w]\n",
    "  return dst\n",
    "\n",
    "\n",
    "def align_phase_rotation(new_img, infoDict):\n",
    "  \"\"\"\n",
    "    Alignment of the phase and rotation differences caused by different camera locations and\n",
    "    optical accuracy\n",
    "\n",
    "    This function aligns the phase and rotation differences in an image based on calibration data.\n",
    "    Parameters:\n",
    "    - new_img: The input image to be aligned.\n",
    "    - infoDict: Dictionary containing calibration data, including:\n",
    "        - 'Calibrated Optical Center X': X coordinate of the optical center.\n",
    "        - 'Calibrated Optical Center Y': Y coordinate of the optical center.\n",
    "        - 'Calibrated H Matrix': Homography matrix for perspective transformation.\n",
    "    Returns:\n",
    "    - new_img: The aligned (to an ideal plane) image as a NumPy array.\n",
    "  \"\"\"\n",
    "  \n",
    "  rows, cols = new_img.shape\n",
    "  H = np.asarray([float(elem) for elem in infoDict['Calibrated H Matrix'].split(\",\")]).reshape(3,3)\n",
    "  new_img = cv2.warpPerspective(new_img, H, (cols, rows))\n",
    "  return new_img\n",
    "\n",
    "\n",
    "def crop_center(img, crop_tamanho):\n",
    "    \"\"\"\n",
    "        Crop the center of the image.\n",
    "        Parameters:\n",
    "            - img: The input image to be cropped.\n",
    "            - crop_tamanho: The size of the square crop.\n",
    "        Returns:\n",
    "            - imagem_cropped: The cropped image as a NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # get the dimensions of the image\n",
    "    altura = img.shape[0]\n",
    "    largura = img.shape[1]\n",
    "\n",
    "    # calculate the starting and ending coordinates for the crop\n",
    "    start_x = largura // 2 - crop_tamanho // 2\n",
    "    start_y = altura // 2 - crop_tamanho // 2\n",
    "    end_x = start_x + crop_tamanho\n",
    "    end_y = start_y + crop_tamanho\n",
    "\n",
    "    # crop the image\n",
    "    imagem_cropped = img[start_y:end_y, start_x:end_x]\n",
    "    return imagem_cropped\n",
    "\n",
    "\n",
    "def zoom_center(img, zoom_factor=1.5):\n",
    "    \"\"\"\n",
    "        Zoom in on the center of the image.\n",
    "        Parameters:\n",
    "            - img: The input image to be zoomed.\n",
    "            - zoom_factor: The factor by which to zoom in.\n",
    "        Returns:\n",
    "            - img_zoomed: The zoomed image as a NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    y_size = img.shape[0]\n",
    "    x_size = img.shape[1]\n",
    "\n",
    "    # define new boundaries\n",
    "    x1 = int(0.5*x_size*(1-1/zoom_factor))\n",
    "    x2 = int(x_size-0.5*x_size*(1-1/zoom_factor))\n",
    "    y1 = int(0.5*y_size*(1-1/zoom_factor))\n",
    "    y2 = int(y_size-0.5*y_size*(1-1/zoom_factor))\n",
    "\n",
    "    # first crop image then scale\n",
    "    img_cropped = img[y1:y2,x1:x2]\n",
    "    return cv2.resize(img_cropped, None, fx=zoom_factor, fy=zoom_factor)\n",
    "\n",
    "\n",
    "def process_image(imgPath):\n",
    "    \"\"\"\n",
    "        Process the image by applying vignette correction, undistortion, and alignment.\n",
    "        Parameters:\n",
    "            - imgPath: Path to the image file.\n",
    "        Returns:\n",
    "            - new_img: The processed image as a NumPy array.\n",
    "    \"\"\"\n",
    "    \n",
    "    # constant for the reference image size\n",
    "    IMG_REF_SHAPE = (2570, 1925)\n",
    "\n",
    "    # get xml metadata for camera corrections\n",
    "    infoDict = get_xml_metadata(imgPath)\n",
    "\n",
    "    # custom pipeline for jpg images, because they have a different resolution \n",
    "    if imgPath[-3:] == 'JPG':\n",
    "            new_img = cv2.imread(imgPath)\n",
    "            new_img = zoom_center(new_img, 1.3)\n",
    "            new_img = cv2.resize(new_img, IMG_REF_SHAPE)\n",
    "            new_img = crop_center(new_img, 1500)\n",
    "            return new_img\n",
    "\n",
    "\n",
    "    # apply vignette correction\n",
    "    new_img = vig_correct(imgPath, infoDict)\n",
    "\n",
    "    # undistort image\n",
    "    new_img = undistort(new_img, infoDict)\n",
    "\n",
    "    # align phase and rotation\n",
    "    new_img = align_phase_rotation(new_img, infoDict)\n",
    "    \n",
    "    # crop center\n",
    "    new_img = crop_center(new_img, 1500)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second part: Image Smoothing, Edge Detection, and Alignment using ECC\n",
    "\n",
    "Now that the images are properly calibrated and show roughly the same area, we need to align the images based on structural features. Here's how each function contributes to the process:\n",
    "\n",
    "8. **`smooth_image`**: Applies a Gaussian filter to reduce image noise and detail. This helps enhance the performance of edge detection by minimizing irrelevant high-frequency content.\n",
    "\n",
    "9. **`edge_detection`**: Uses the Sobel operator to compute gradients along the x and y directions and calculates the gradient magnitude. The result highlights the edges in the image, which are crucial features for alignment.\n",
    "\n",
    "10. **`align_images_using_ecc`**: Aligns a `target_image` to a `reference_image` using the Enhanced Correlation Coefficient (ECC) algorithm. The function:\n",
    "  - Converts JPG images to grayscale (if applicable).\n",
    "  - Applies smoothing and edge detection to both images.\n",
    "  - Defines a homography warp model and calculates a transformation matrix using `cv2.findTransformECC`.\n",
    "  - Applies the computed warp matrix to the `target_image`, aligning it with the `reference_image`.\n",
    "\n",
    "This pipeline is particularly useful when working with multi-temporal or multi-spectral images where direct pixel-wise comparison may not be sufficient due to varying intensity distributions or minor misalignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T12:59:18.273660Z",
     "iopub.status.busy": "2024-05-27T12:59:18.273155Z",
     "iopub.status.idle": "2024-05-27T12:59:18.289210Z",
     "shell.execute_reply": "2024-05-27T12:59:18.288157Z",
     "shell.execute_reply.started": "2024-05-27T12:59:18.273610Z"
    },
    "id": "Ptm8mwjrudQq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def smooth_image(image, sigma=1):\n",
    "    \"\"\"\n",
    "        Apply Gaussian smoothing to the image.\n",
    "        Parameters:\n",
    "            - image: The input image to be smoothed.\n",
    "            - sigma: Standard deviation for Gaussian kernel.\n",
    "        Returns:\n",
    "            - smoothed_image: The smoothed image as a NumPy array.\n",
    "    \"\"\"\n",
    "    return gaussian_filter(image, sigma=sigma)\n",
    "\n",
    "\n",
    "def edge_detection(image):\n",
    "    \"\"\"\n",
    "        Apply Sobel filter to detect edges in the image.\n",
    "        Parameters:\n",
    "            - image: The input image to be processed.\n",
    "        Returns:\n",
    "            - magnitude: The magnitude of the gradient, representing edge strength.\n",
    "    \"\"\"\n",
    "\n",
    "    grad_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    magnitude = cv2.magnitude(grad_x, grad_y)\n",
    "    return magnitude\n",
    "\n",
    "\n",
    "def align_images_using_ecc(reference_image, target_image, jpg=False):\n",
    "    \"\"\"\n",
    "        Align two images using the Enhanced Correlation Coefficient (ECC) algorithm.\n",
    "        Parameters:\n",
    "            - reference_image: The reference image to align to.\n",
    "            - target_image: The target image to be aligned.\n",
    "            - jpg: Boolean indicating if the target image is a JPG file.\n",
    "        Returns:\n",
    "            - aligned_image: The aligned target image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # JPG images do not have the same exif data as the reference TIFF images,\n",
    "    # therefore they need a different treatment\n",
    "    if jpg:\n",
    "        # save colored jpg\n",
    "        colored_jpg = target_image\n",
    "        # create temporary greyscale img\n",
    "        target_image = cv2.cvtColor(target_image, cv2.COLOR_BGR2GRAY) \n",
    "    \n",
    "    # smooth the images\n",
    "    reference_image_smoothed = smooth_image(reference_image)\n",
    "    target_image_smoothed = smooth_image(target_image)\n",
    "\n",
    "    # apply edge detection\n",
    "    base_edges = edge_detection(reference_image_smoothed)\n",
    "    target_edges = edge_detection(target_image_smoothed)\n",
    "\n",
    "    # convert images to float32 for ECC algorithm\n",
    "    base_edges = base_edges.astype(np.float32)\n",
    "    target_edges = target_edges.astype(np.float32)\n",
    "    \n",
    "    # define the motion model\n",
    "    warp_mode = cv2.MOTION_HOMOGRAPHY\n",
    "    warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "\n",
    "    # set the number of iterations and termination criteria\n",
    "    if jpg:\n",
    "        # increase iterations for jpg images, beacause they went through lees processing\n",
    "        number_of_iterations = 500 \n",
    "    else:\n",
    "        number_of_iterations = 25\n",
    "    termination_eps = 1e-10\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations, termination_eps)\n",
    "\n",
    "\n",
    "    # apply the ECC algorithm to find the warp matrix\n",
    "    cc, warp_matrix = cv2.findTransformECC(base_edges, target_edges, warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "    if jpg:\n",
    "        target_image = colored_jpg\n",
    "\n",
    "    # warp the target image to align with the base image\n",
    "    aligned_image = cv2.warpPerspective(target_image, warp_matrix, (reference_image.shape[1], reference_image.shape[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "    \n",
    "    return aligned_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting It All Together: Image Preprocessing Pipeline Driver\n",
    "\n",
    "This section orchestrates the entire image preprocessing pipeline, combining image selection, processing, alignment, normalization, cropping, and saving into a single loop. Here's a breakdown of the workflow:\n",
    "\n",
    "- **Directory Setup & File Collection**:  \n",
    "  The script changes the working directory to `./raw-imgs` and collects all `.JPG` and `.TIF` files using `glob`. The file list is sorted to maintain consistent band order.\n",
    "\n",
    "- **Batch Processing with Sliding Window**:  \n",
    "  Using a sliding window (`slc = 5`), the script iterates through the images in sets of five — assumed to be in the order `[JPG, G, NIR, R, RE]`.\n",
    "\n",
    "- **Reference Selection & Alignment**:  \n",
    "  The **G band** image is chosen as the reference (`ref_img`), and the remaining bands are aligned to it using the ECC-based alignment function:\n",
    "  - `target_jpg` is aligned with the `jpg=True` flag (special grayscale treatment).\n",
    "  - `target_nir`, `target_r`, and `target_re` are aligned normally.\n",
    "\n",
    "- **Normalization and Cropping**:  \n",
    "  Each aligned image is normalized to the 8-bit range `[0, 255]` and then cropped to a 1000x1000 center square for consistency and comparability.\n",
    "\n",
    "- **Saving Preprocessed Images**:  \n",
    "  All processed and aligned images are saved into the `preprocessed-imgs` folder with a `processed-` prefix.\n",
    "\n",
    "- **Progress Logging**:  \n",
    "  After each batch of 5 images is processed and saved, a status message is printed to the console.\n",
    "\n",
    "This driver code ties together all prior functions and forms the backbone of the preprocessing routine, ensuring the images are ready for downstream analysis (e.g., model training or feature extraction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T12:59:18.292799Z",
     "iopub.status.busy": "2024-05-27T12:59:18.291057Z",
     "iopub.status.idle": "2024-05-27T13:02:32.793050Z",
     "shell.execute_reply": "2024-05-27T13:02:32.791341Z",
     "shell.execute_reply.started": "2024-05-27T12:59:18.292683Z"
    },
    "id": "GJKIZt-7v-n1",
    "outputId": "6cd1b2ad-0890-41a7-eaa7-298a553072fa",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images DJI_20250127100947_0154_D.JPG - DJI_20250127100947_0154_MS_RE.TIF processed and saved\n",
      "images DJI_20250127100949_0155_D.JPG - DJI_20250127100949_0155_MS_RE.TIF processed and saved\n",
      "images DJI_20250127100952_0156_D.JPG - DJI_20250127100952_0156_MS_RE.TIF processed and saved\n",
      "images DJI_20250127100954_0157_D.JPG - DJI_20250127100954_0157_MS_RE.TIF processed and saved\n",
      "images DJI_20250127100957_0158_D.JPG - DJI_20250127100957_0158_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101000_0159_D.JPG - DJI_20250127101000_0159_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101002_0160_D.JPG - DJI_20250127101002_0160_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101005_0161_D.JPG - DJI_20250127101005_0161_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101007_0162_D.JPG - DJI_20250127101007_0162_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101010_0163_D.JPG - DJI_20250127101010_0163_MS_RE.TIF processed and saved\n",
      "images DJI_20250127101012_0164_D.JPG - DJI_20250127101012_0164_MS_RE.TIF processed and saved\n"
     ]
    }
   ],
   "source": [
    "# DRIVER\n",
    "IMG_REF_SHAPE = (2570, 1925)\n",
    "\n",
    "# Take relative paths, because chenged os current dir\n",
    "os.chdir(\"./raw-imgs\")\n",
    "types = ('*.JPG', '*.TIF') # the tuple of file types\n",
    "files_grabbed = []\n",
    "for files in types:\n",
    "    files_grabbed.extend(glob.glob(files))\n",
    "    \n",
    "input_imgs = sorted(files_grabbed)\n",
    "\n",
    "i = cycle(input_imgs)\n",
    "slc = 5\n",
    "for _ in range(math.ceil(len(input_imgs)/slc)):\n",
    "    cur_imgs = list(islice(i,slc))\n",
    "    \n",
    "    ref_img = process_image(cur_imgs[1]) # G BAND -> REFERENCE\n",
    "    target_jpg = process_image(cur_imgs[0])\n",
    "    target_nir = process_image(cur_imgs[2])\n",
    "    target_r = process_image(cur_imgs[3])\n",
    "    target_re = process_image(cur_imgs[4])\n",
    "\n",
    "    # align image to G BAND\n",
    "    aligned_jpg_image = align_images_using_ecc(ref_img, target_jpg, True)\n",
    "    aligned_nir_image = align_images_using_ecc(ref_img, target_nir)\n",
    "    aligned_r_image = align_images_using_ecc(ref_img, target_r)\n",
    "    aligned_re_image = align_images_using_ecc(ref_img, target_re)\n",
    "\n",
    "    # remember to crop and normalize reference/target img here:\n",
    "    # normalize the image to range 0 to 255 and convert to uint8\n",
    "    aligned_jpg_image = cv2.normalize(aligned_jpg_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    aligned_nir_image = cv2.normalize(aligned_nir_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    aligned_r_image = cv2.normalize(aligned_r_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    aligned_re_image = cv2.normalize(aligned_re_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    aligned_g_image = cv2.normalize(ref_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "    # crop again\n",
    "    aligned_jpg_image = crop_center(aligned_jpg_image, 1000)\n",
    "    aligned_nir_image = crop_center(aligned_nir_image, 1000)\n",
    "    aligned_r_image = crop_center(aligned_r_image, 1000)\n",
    "    aligned_re_image = crop_center(aligned_re_image, 1000)\n",
    "    aligned_g_image = crop_center(aligned_g_image, 1000)\n",
    "\n",
    "    # save\n",
    "    cv2.imwrite(f\"{os.path.dirname(os.getcwd())}/preprocessed-imgs/processed-{cur_imgs[0]}\", aligned_jpg_image)\n",
    "    cv2.imwrite(f\"{os.path.dirname(os.getcwd())}/preprocessed-imgs/processed-{cur_imgs[1]}\", aligned_g_image)\n",
    "    cv2.imwrite(f\"{os.path.dirname(os.getcwd())}/preprocessed-imgs/processed-{cur_imgs[2]}\", aligned_nir_image)\n",
    "    cv2.imwrite(f\"{os.path.dirname(os.getcwd())}/preprocessed-imgs/processed-{cur_imgs[3]}\", aligned_r_image)\n",
    "    cv2.imwrite(f\"{os.path.dirname(os.getcwd())}/preprocessed-imgs/processed-{cur_imgs[4]}\", aligned_re_image)\n",
    "\n",
    "    \n",
    "    print(f\"images {cur_imgs[0]} - {cur_imgs[4]} processed and saved\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5080300,
     "sourceId": 8510679,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5084442,
     "sourceId": 8516220,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5651986,
     "sourceId": 9328743,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6623428,
     "sourceId": 10689864,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6623527,
     "sourceId": 10689982,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6624935,
     "sourceId": 10692058,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "cerradao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
