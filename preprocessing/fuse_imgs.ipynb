{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dad557d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T14:01:58.958994Z",
     "iopub.status.busy": "2025-03-20T14:01:58.958630Z",
     "iopub.status.idle": "2025-03-20T14:02:07.288918Z",
     "shell.execute_reply": "2025-03-20T14:02:07.287679Z"
    },
    "papermill": {
     "duration": 8.336445,
     "end_time": "2025-03-20T14:02:07.291051",
     "exception": false,
     "start_time": "2025-03-20T14:01:58.954606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load the modules\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "from itertools import cycle , islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0ec4fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T14:02:07.297810Z",
     "iopub.status.busy": "2025-03-20T14:02:07.297282Z",
     "iopub.status.idle": "2025-03-20T14:02:07.304103Z",
     "shell.execute_reply": "2025-03-20T14:02:07.303008Z"
    },
    "papermill": {
     "duration": 0.011961,
     "end_time": "2025-03-20T14:02:07.305925",
     "exception": false,
     "start_time": "2025-03-20T14:02:07.293964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_annons(path_to_csv):\n",
    "    df = pd.read_csv(path_to_csv, sep=',', names=['image_path', 'xmin', 'ymin', 'xmax', 'ymax', 'label'])\n",
    "    return df\n",
    "    \n",
    "def reformat(filename):\n",
    "    return f'{filename[0:42][:-6]}GS.jpg'\n",
    "\n",
    "def compute_similarity(img1, img2):\n",
    "    \"\"\"Compute SSIM between two images, handling grayscale and RGB cases.\"\"\"\n",
    "    if len(img1.shape) == 3:  # RGB image\n",
    "        img1_gray = np.mean(img1, axis=2)\n",
    "    else:  # Already grayscale\n",
    "        img1_gray = img1\n",
    "\n",
    "    if len(img2.shape) == 3:\n",
    "        img2_gray = np.mean(img2, axis=2)\n",
    "    else:\n",
    "        img2_gray = img2\n",
    "\n",
    "    return ssim(img1_gray, img2_gray, data_range=img2_gray.max() - img2_gray.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b11750e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T14:02:07.312044Z",
     "iopub.status.busy": "2025-03-20T14:02:07.311669Z",
     "iopub.status.idle": "2025-03-20T14:03:39.718534Z",
     "shell.execute_reply": "2025-03-20T14:03:39.717298Z"
    },
    "papermill": {
     "duration": 92.413031,
     "end_time": "2025-03-20T14:03:39.721501",
     "exception": false,
     "start_time": "2025-03-20T14:02:07.308470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images transformed and saved into train, test, and val folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from itertools import cycle, islice\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: Preprocess annotation CSVs.\n",
    "# (Define your own function or adjust as needed.)\n",
    "def preprocess_annons(csv_path):\n",
    "    # Example: read CSV with pandas; assumes a column \"image_path\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "\n",
    "def gram_schmidt_fusion_rgb(multispectral, pseudo_rgb, alpha=2):\n",
    "    \"\"\"\n",
    "    Fuse the multispectral information into a pseudo-RGB image using an intensity substitution approach,\n",
    "    with an adjustable multispectral boost factor.\n",
    "\n",
    "    Args:\n",
    "        multispectral (np.ndarray): Array of shape (H, W, C_ms) from all bands.\n",
    "        pseudo_rgb (np.ndarray): Array of shape (H, W, 3) composed from selected bands (e.g., R, G, B).\n",
    "        alpha (float): Boost factor to increase the multispectral impact.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Fused pseudo-RGB image (H, W, 3) as uint8.\n",
    "    \"\"\"\n",
    "    pseudo_rgb = pseudo_rgb.astype(np.float32)\n",
    "    multispectral = multispectral.astype(np.float32)\n",
    "\n",
    "    intensity_rgb = np.mean(pseudo_rgb, axis=-1, keepdims=True)\n",
    "    intensity_ms = np.mean(multispectral, axis=-1, keepdims=True)\n",
    "    # Boost the multispectral intensity before computing the ratio\n",
    "    ratio = (alpha * intensity_ms) / (intensity_rgb + 1e-8)  # avoid division by zero\n",
    "\n",
    "    fused = pseudo_rgb * ratio\n",
    "    fused = np.clip(fused, 0, 255).astype(np.uint8)\n",
    "    return fused\n",
    "\n",
    "# -------------------------------\n",
    "# Define output directory and create subdirectories for train, val, test\n",
    "out_dir = \"/kaggle/working/GS_transformed\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "train_dir = os.path.join(out_dir, \"train\")\n",
    "val_dir = os.path.join(out_dir, \"valid\")\n",
    "test_dir = os.path.join(out_dir, \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# ------------------------------- change here \n",
    "# Load annotation CSVs and extract lists of image basenames\n",
    "TRAIN_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/train_annotations.csv\"\n",
    "VAL_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/val_annotations.csv\"\n",
    "TEST_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/test_annotations.csv\"\n",
    "# -------------------------------\n",
    "file_paths = [TRAIN_ANNOTATIONS_FILE_PATH, VAL_ANNOTATIONS_FILE_PATH, TEST_ANNOTATIONS_FILE_PATH]\n",
    "train_paths = []\n",
    "val_paths = []\n",
    "test_paths = []\n",
    "i = 0\n",
    "for f in file_paths:\n",
    "    annotations = preprocess_annons(f)\n",
    "    # Assumes the CSV has a column \"image_path\" with full file names.\n",
    "    unique_names = annotations[\"image_path\"].unique().tolist()\n",
    "    # Optionally, remove the header element if necessary\n",
    "    if i == 0:\n",
    "        train_paths = [os.path.basename(name) for name in unique_names]\n",
    "    elif i == 1:\n",
    "        test_paths = [os.path.basename(name) for name in unique_names]\n",
    "    elif i == 2:\n",
    "        val_paths = [os.path.basename(name) for name in unique_names]\n",
    "    i += 1\n",
    "\n",
    "# -------------------------------\n",
    "# Main processing of images for GS fusion\n",
    "current_imgs_dir = \"/kaggle/input/all-images-preprocessed/all_processed_imgs\"\n",
    "os.chdir(current_imgs_dir)\n",
    "\n",
    "types = ('*.JPG', '*.TIF')\n",
    "files_grabbed = []\n",
    "for pattern in types:\n",
    "    files_grabbed.extend(glob.glob(pattern))\n",
    "    \n",
    "input_imgs = sorted(files_grabbed)  # process first 100 images\n",
    "i = cycle(input_imgs)\n",
    "slc = 5  # number of images per group\n",
    "\n",
    "# Process images in groups of 5\n",
    "for _ in range(math.ceil(len(input_imgs) / slc)):\n",
    "    cur_imgs = list(islice(i, slc))\n",
    "    if len(cur_imgs) < slc:\n",
    "        break\n",
    "        \n",
    "    # Determine destination folder based on current image's basename.\n",
    "    base_name = os.path.basename(cur_imgs[0][:-4]) + '_GS.jpg'\n",
    "\n",
    "\n",
    "    # Check in train, test, and val lists\n",
    "    if base_name in train_paths:\n",
    "        dest_folder = train_dir\n",
    "        #print(f\"training image {base_name} found!\")\n",
    "    elif base_name in val_paths:\n",
    "        dest_folder = val_dir\n",
    "    elif base_name in test_paths:\n",
    "        dest_folder = test_dir\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Load images from current group\n",
    "    ref_img = np.asarray(Image.open(cur_imgs[1]))\n",
    "    target_jpg = np.asarray(Image.open(cur_imgs[0])) * 0.125\n",
    "    target_nir = np.asarray(Image.open(cur_imgs[2])) \n",
    "    target_r = np.asarray(Image.open(cur_imgs[3])) \n",
    "    target_re = np.asarray(Image.open(cur_imgs[4])) \n",
    "    \n",
    "    # Stack images to form multispectral and pseudo-RGB inputs\n",
    "    fused_imgs = np.dstack((ref_img, target_jpg, target_nir, target_r, target_re))\n",
    "    # Example pseudo-RGB: using target_r for red, ref_img for green, and target_nir for blue.\n",
    "    pseudo_rgb = np.dstack((target_r, ref_img, target_nir))\n",
    "    \n",
    "    fused_pseudo_rgb = gram_schmidt_fusion_rgb(multispectral=fused_imgs, pseudo_rgb=pseudo_rgb)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    # Check in train, test, and val lists\n",
    "    if base_name in train_paths:\n",
    "        dest_folder = train_dir\n",
    "    elif base_name in val_paths:\n",
    "        dest_folder = val_dir\n",
    "    elif base_name in test_paths:\n",
    "        dest_folder = test_dir\n",
    "    \n",
    "    output_filename = os.path.join(dest_folder, f\"{os.path.splitext(base_name)[0]}.jpg\")\n",
    "    Image.fromarray(fused_pseudo_rgb).save(output_filename)\n",
    "    # Optionally, print confirmation:\n",
    "    # print(f\"Saved {output_filename}\")\n",
    "\n",
    "print(\"All images transformed and saved into train, test, and val folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3c22ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T14:03:39.727428Z",
     "iopub.status.busy": "2025-03-20T14:03:39.727054Z",
     "iopub.status.idle": "2025-03-20T14:03:39.739394Z",
     "shell.execute_reply": "2025-03-20T14:03:39.738269Z"
    },
    "papermill": {
     "duration": 0.017294,
     "end_time": "2025-03-20T14:03:39.741222",
     "exception": false,
     "start_time": "2025-03-20T14:03:39.723928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/GS_transformed/test/_annotations.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "TRAIN_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/train_annotations.csv\"\n",
    "VAL_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/val_annotations.csv\"\n",
    "TEST_ANNOTATIONS_FILE_PATH = \"/kaggle/input/new-split/test_annotations.csv\"\n",
    "\n",
    "shutil.copyfile(TRAIN_ANNOTATIONS_FILE_PATH, train_dir + \"/_annotations.csv\")\n",
    "shutil.copyfile(VAL_ANNOTATIONS_FILE_PATH, val_dir + \"/_annotations.csv\")\n",
    "shutil.copyfile(TEST_ANNOTATIONS_FILE_PATH, test_dir + \"/_annotations.csv\")\n",
    "\n",
    "\n",
    "# os.rename(\"/kaggle/working/GS_transformed/train/train_annotations.csv\", \"/kaggle/working/GS_transformed/train/_annotations.csv\")\n",
    "# os.rename(\"/kaggle/working/GS_transformed/valid/val_annotations.csv\", \"/kaggle/working/GS_transformed/valid/_annotations.csv\")\n",
    "# os.rename(\"/kaggle/working/GS_transformed/test/test_annotations.csv\", \"/kaggle/working/GS_transformed/test/_annotations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5116890,
     "sourceId": 8560729,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5711226,
     "sourceId": 9406589,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6886957,
     "sourceId": 11054272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6887494,
     "sourceId": 11055125,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6895183,
     "sourceId": 11065491,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6905828,
     "sourceId": 11080012,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6906664,
     "sourceId": 11081358,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6912545,
     "sourceId": 11089727,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.633811,
   "end_time": "2025-03-20T14:03:41.570265",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T14:01:55.936454",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
